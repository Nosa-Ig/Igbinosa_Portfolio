{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAslINHFynpT",
        "outputId": "83396683-ac69-4a00-8c5b-ba6e4416a09c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Store with maximum total sales:\n",
            " Store  Total_Sales\n",
            "    20 301397792.46\n",
            "\n",
            "Store with maximum sales standard deviation:\n",
            " Store         mean           std  coef_mean_to_std\n",
            "    14 2.020978e+06 317569.949476          6.363884\n",
            "\n",
            "Q3 2012 growth vs Q2 2012 by store (top 10):\n",
            "Quarter  Q3_growth_vs_Q2\n",
            "Store                   \n",
            "7               0.133308\n",
            "16              0.084884\n",
            "35              0.044666\n",
            "26              0.039555\n",
            "39              0.024784\n",
            "41              0.024570\n",
            "44              0.024346\n",
            "24              0.016521\n",
            "40              0.011428\n",
            "23              0.008254\n",
            "\n",
            "Mean non-holiday sales (all stores): 1,041,256.38\n",
            "Holiday weeks (dates) with higher-than-mean non-holiday sales:\n",
            "      Date  Weekly_Sales\n",
            "2011-11-25  1.479858e+06\n",
            "2010-11-26  1.462689e+06\n",
            "2012-02-10  1.111320e+06\n",
            "2010-02-12  1.074148e+06\n",
            "2012-09-07  1.074001e+06\n",
            "2011-02-11  1.051915e+06\n",
            "\n",
            "Monthly sales (first 10 rows):\n",
            " Year  Month  Monthly_Sales\n",
            " 2010      2   190332983.04\n",
            " 2010      3   181919802.50\n",
            " 2010      4   231412368.05\n",
            " 2010      5   186710934.34\n",
            " 2010      6   192246172.36\n",
            " 2010      7   232580125.98\n",
            " 2010      8   187640110.89\n",
            " 2010      9   177267896.37\n",
            " 2010     10   217161824.02\n",
            " 2010     11   202853370.14\n",
            "\n",
            "Semester (H1/H2) sales by year:\n",
            " Year Semester  Semester_Sales\n",
            " 2010       H1    9.826223e+08\n",
            " 2010       H2    1.306264e+09\n",
            " 2011       H1    1.127340e+09\n",
            " 2011       H2    1.320860e+09\n",
            " 2012       H1    1.210765e+09\n",
            " 2012       H2    7.893674e+08\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# ----------------------------\n",
        "# LOAD & PREP\n",
        "# ----------------------------\n",
        "df = pd.read_csv(\"Walmart_Store_sales.csv\")\n",
        "df['Date'] = pd.to_datetime(df['Date'], format='%d-%m-%Y')\n",
        "df = df.sort_values(['Store','Date']).reset_index(drop=True)\n",
        "\n",
        "# Sanity: expected columns\n",
        "expected = {'Store','Date','Weekly_Sales','Holiday_Flag','Temperature','Fuel_Price','CPI','Unemployment'}\n",
        "missing = expected - set(df.columns)\n",
        "assert not missing, f\"Missing columns: {missing}\"\n",
        "\n",
        "# Convenience\n",
        "df['Year'] = df['Date'].dt.year\n",
        "df['Month'] = df['Date'].dt.month\n",
        "df['Quarter'] = df['Date'].dt.quarter\n",
        "df['Semester'] = np.where(df['Month']<=6, 'H1', 'H2')\n",
        "\n",
        "# ----------------------------\n",
        "# TASK 1: Which store has maximum sales (total)\n",
        "# ----------------------------\n",
        "store_total_sales = df.groupby('Store', as_index=False)['Weekly_Sales'].sum().rename(columns={'Weekly_Sales':'Total_Sales'})\n",
        "store_with_max_sales = store_total_sales.sort_values('Total_Sales', ascending=False).head(1)\n",
        "\n",
        "# ----------------------------\n",
        "# TASK 2: Which store has maximum standard deviation & coefficient (std/mean)\n",
        "# ----------------------------\n",
        "store_stats = df.groupby('Store', as_index=False)['Weekly_Sales'].agg(['mean','std']).reset_index()\n",
        "store_stats['coef_mean_to_std'] = store_stats['mean'] / store_stats['std']\n",
        "store_with_max_std = store_stats.sort_values('std', ascending=False).head(1)\n",
        "\n",
        "# ----------------------------\n",
        "# TASK 3: Store(s) with good quarterly growth in Q3 2012\n",
        "# Definition: (Q3 2012 total vs Q2 2012 total) % growth\n",
        "# ----------------------------\n",
        "df_2012 = df[df['Year']==2012].copy()\n",
        "q_sales_2012 = df_2012.pivot_table(index='Store', columns='Quarter', values='Weekly_Sales', aggfunc='sum').fillna(0)\n",
        "if 2 in q_sales_2012.columns and 3 in q_sales_2012.columns:\n",
        "    q_sales_2012['Q3_growth_vs_Q2'] = (q_sales_2012[3] - q_sales_2012[2]) / q_sales_2012[2].replace(0, np.nan)\n",
        "    good_growth = q_sales_2012.sort_values('Q3_growth_vs_Q2', ascending=False).dropna(subset=['Q3_growth_vs_Q2'])\n",
        "else:\n",
        "    good_growth = pd.DataFrame(columns=['Q3_growth_vs_Q2'])\n",
        "\n",
        "# ----------------------------\n",
        "# TASK 4: Holidays with higher sales than mean non-holiday sales (all stores)\n",
        "# ----------------------------\n",
        "mean_non_holiday = df.loc[df['Holiday_Flag']==0, 'Weekly_Sales'].mean()\n",
        "# Aggregate each holiday week date across all stores; mark dates as \"holiday dates\"\n",
        "holiday_weeks = df.loc[df['Holiday_Flag']==1].groupby('Date', as_index=False)['Weekly_Sales'].mean()\n",
        "holidays_higher = holiday_weeks[holiday_weeks['Weekly_Sales'] > mean_non_holiday].sort_values('Weekly_Sales', ascending=False)\n",
        "\n",
        "# ----------------------------\n",
        "# TASK 5: Monthly & Semester views (units = Weekly_Sales; we'll sum)\n",
        "# ----------------------------\n",
        "monthly_view = df.groupby(['Year','Month'], as_index=False)['Weekly_Sales'].sum().rename(columns={'Weekly_Sales':'Monthly_Sales'})\n",
        "semester_view = df.groupby(['Year','Semester'], as_index=False)['Weekly_Sales'].sum().rename(columns={'Weekly_Sales':'Semester_Sales'})\n",
        "\n",
        "# ---- Print concise insights ----\n",
        "print(\"\\nStore with maximum total sales:\")\n",
        "print(store_with_max_sales.to_string(index=False))\n",
        "\n",
        "print(\"\\nStore with maximum sales standard deviation:\")\n",
        "print(store_with_max_std[['Store','mean','std','coef_mean_to_std']].to_string(index=False))\n",
        "\n",
        "print(\"\\nQ3 2012 growth vs Q2 2012 by store (top 10):\")\n",
        "print(good_growth[['Q3_growth_vs_Q2']].head(10).to_string())\n",
        "\n",
        "print(f\"\\nMean non-holiday sales (all stores): {mean_non_holiday:,.2f}\")\n",
        "print(\"Holiday weeks (dates) with higher-than-mean non-holiday sales:\")\n",
        "print(holidays_higher.to_string(index=False))\n",
        "\n",
        "print(\"\\nMonthly sales (first 10 rows):\")\n",
        "print(monthly_view.head(10).to_string(index=False))\n",
        "\n",
        "print(\"\\nSemester (H1/H2) sales by year:\")\n",
        "print(semester_view.to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "import numpy as np\n",
        "\n",
        "# ----------------------------\n",
        "# FILTER STORE 1 & FEATURE ENGINEERING\n",
        "# ----------------------------\n",
        "s1 = df[df['Store']==1].copy().sort_values('Date')\n",
        "s1 = s1.reset_index(drop=True)\n",
        "\n",
        "# index starting at 1 for earliest date across ALL data (as required)\n",
        "global_start = df['Date'].min()\n",
        "s1['date_index'] = (s1['Date'] - global_start).dt.days // 7 + 1  # weekly index\n",
        "s1['days_since_start'] = (s1['Date'] - global_start).dt.days\n",
        "\n",
        "# (optional) simple seasonality features from weekly data\n",
        "s1['weekofyear'] = s1['Date'].dt.isocalendar().week.astype(int)\n",
        "s1['year'] = s1['Date'].dt.year\n",
        "\n",
        "feat_cols = [\n",
        "    'date_index',           # required\n",
        "    'days_since_start',     # required \"days\"\n",
        "    'Temperature',\n",
        "    'Fuel_Price',\n",
        "    'CPI',\n",
        "    'Unemployment',\n",
        "    'Holiday_Flag',\n",
        "    'weekofyear'            # mild seasonal signal\n",
        "]\n",
        "\n",
        "s1 = s1.dropna(subset=feat_cols + ['Weekly_Sales']).copy()\n",
        "\n",
        "X = s1[feat_cols].values\n",
        "y = s1['Weekly_Sales'].values\n",
        "sample_w = np.where(s1['Holiday_Flag']==1, 5.0, 1.0)  # holiday weighting\n",
        "\n",
        "# ----------------------------\n",
        "# TIME-AWARE TRAIN/TEST SPLIT\n",
        "# (last 20% as test to respect chronology)\n",
        "# ----------------------------\n",
        "n = len(s1)\n",
        "split_idx = int(n*0.8)\n",
        "X_train, X_test = X[:split_idx], X[split_idx:]\n",
        "y_train, y_test = y[:split_idx], y[split_idx:]\n",
        "w_train = sample_w[:split_idx]\n",
        "w_test  = sample_w[split_idx:]\n",
        "\n",
        "# ----------------------------\n",
        "# MODELS\n",
        "# ----------------------------\n",
        "candidates = {\n",
        "    'LinearRegression': make_pipeline(StandardScaler(with_mean=True, with_std=True), LinearRegression()),\n",
        "    'Ridge':            make_pipeline(StandardScaler(with_mean=True, with_std=True), Ridge(alpha=5.0, random_state=0)),\n",
        "    'Lasso':            make_pipeline(StandardScaler(with_mean=True, with_std=True), Lasso(alpha=0.001, random_state=0, max_iter=20000))\n",
        "}\n",
        "\n",
        "results = []\n",
        "for name, model in candidates.items():\n",
        "    model.fit(X_train, y_train, **({'linearregression__sample_weight': w_train} if name=='LinearRegression' else\n",
        "                                   {'ridge__sample_weight': w_train} if name=='Ridge' else\n",
        "                                   {'lasso__sample_weight': w_train}))\n",
        "    y_pred = model.predict(X_test)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    mape = mean_absolute_percentage_error(y_test, y_pred)\n",
        "    results.append((name, rmse, mape))\n",
        "\n",
        "res_df = pd.DataFrame(results, columns=['Model','RMSE','MAPE']).sort_values('RMSE')\n",
        "print(\"\\nStore 1 — test set performance (lower is better):\")\n",
        "print(res_df.to_string(index=False))\n",
        "\n",
        "best_name = res_df.iloc[0]['Model']\n",
        "best_model = candidates[best_name]\n",
        "print(f\"\\nSelected model: {best_name}\")\n",
        "\n",
        "# Fit on full data (if you want a final model for deployment)\n",
        "best_model.fit(X, y, **({'linearregression__sample_weight': sample_w} if best_name=='LinearRegression' else\n",
        "                         {'ridge__sample_weight': sample_w} if best_name=='Ridge' else\n",
        "                         {'lasso__sample_weight': sample_w}))\n",
        "\n",
        "# Example: next-week forecast (naive feature extension)\n",
        "# Replace the below with your actual future covariates if available\n",
        "last_row = s1.iloc[-1:].copy()\n",
        "future = last_row.copy()\n",
        "future['Date'] = last_row['Date'] + pd.Timedelta(days=7)\n",
        "future['date_index'] = last_row['date_index'] + 1\n",
        "future['days_since_start'] = (future['Date'] - global_start).dt.days\n",
        "future['weekofyear'] = future['Date'].dt.isocalendar().week.astype(int)\n",
        "# Keep other drivers equal to last observed unless you have forecasts\n",
        "X_future = future[feat_cols].values\n",
        "y_next_pred = best_model.predict(X_future)[0]\n",
        "print(f\"\\nNext-week forecast (Store 1, naive drivers): {y_next_pred:,.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inEWH0PY6lfo",
        "outputId": "8606fba7-dde0-41a1-8b03-cb04dc6051d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Store 1 — test set performance (lower is better):\n",
            "           Model          RMSE     MAPE\n",
            "           Ridge 160867.234128 0.089643\n",
            "           Lasso 177619.610461 0.098974\n",
            "LinearRegression 177619.626632 0.098974\n",
            "\n",
            "Selected model: Ridge\n",
            "\n",
            "Next-week forecast (Store 1, naive drivers): 1,619,580.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27389b50",
        "outputId": "f8f8d2b2-bdd9-46d9-f163-4e6bc0976eb7"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive  sample_data\n"
          ]
        }
      ]
    }
  ]
}